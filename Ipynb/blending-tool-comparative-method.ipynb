{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dress-taylor",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.025541,
     "end_time": "2021-06-16T18:30:50.253656",
     "exception": false,
     "start_time": "2021-06-16T18:30:50.228115",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-manchester",
   "metadata": {
    "papermill": {
     "duration": 0.008607,
     "end_time": "2021-06-16T18:30:50.272019",
     "exception": false,
     "start_time": "2021-06-16T18:30:50.263412",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "files are from \n",
    "* https://www.kaggle.com/remekkinas/tps-06-mljar-automl-starter by Remek Kinas\n",
    "* https://www.kaggle.com/remekkinas/tps06blenderdatabase by Remek Kinas\n",
    "* https://www.kaggle.com/remekkinas/autoeda-new-features-lightautoml-rapid-ml by Remek Kinas\n",
    "* https://www.kaggle.com/remekkinas/pytorch-residual-connection-for-tabular by Remek Kinas\n",
    "* https://www.kaggle.com/remekkinas/pytorch-skorch-residual-hyperparameter by Remek Kinas\n",
    "* https://www.kaggle.com/mt77pp/mljar-automl-tps-jun-21 by Piotr\n",
    "* https://www.kaggle.com/kaustubh93/baseline-xgboost-catboost-optuna-shap-tps-06 by Kaustubh B Bhargav\n",
    "* https://www.kaggle.com/pranjalverma08/catboost-with-optuna-starter-tps-06 by Pranjal Verma\n",
    "* https://www.kaggle.com/brookie210/tps-june2021-cat-lgbm-blended by Brooklin Santosh\n",
    "* https://www.kaggle.com/soerendip/xgboost-on-gpu by Klaus\n",
    "* https://www.kaggle.com/pourchot/simple-keras-embedding-in-10-folds/output by Laurent Pourchot\n",
    "* https://www.kaggle.com/pourchot/decision-forest-fed-by-neural-network by Laurent Pourchot\n",
    "* https://www.kaggle.com/pourchot/blending-neural-networks-weights-optimization/output by Laurent Pourchot\n",
    "* https://www.kaggle.com/pourchot/2-concatenated-neural-network-streams?scriptVersionId=65155670 by Laurent Pourchot\n",
    "* https://www.kaggle.com/pourchot/simple-neural-network?scriptVersionId=65477881 by Laurent Pourchot\n",
    "* https://www.kaggle.com/pourchot/3-nn-optimized-conv-embedding-by-col-by-row by Laurent Pourchot\n",
    "* https://www.kaggle.com/alexryzhkov/lightautoml-baseline-tps-june-2021 by Alexander Ryzhkov\n",
    "* https://www.kaggle.com/alexryzhkov/python-keras-nn-residual by Alexander Ryzhkov\n",
    "* https://www.kaggle.com/antonellomartiello/tps-06-mljar-quick-approach-with-eda/output?select=submission.csvby Antonello Martiello\n",
    "* https://www.kaggle.com/nishantdhingra/tps-june-stacking-approach by Nishant Dhingra\n",
    "* https://www.kaggle.com/dlaststark/tps-june-lama-model-baseline?select=LAMA_submission.csv by DLastStark\n",
    "* https://www.kaggle.com/oxzplvifi/tabular-residual-network/execution?select=submission.csv by Oscar Villarreal Escamilla\n",
    "* https://www.kaggle.com/bhavikjain/tps-june-21-eda-models?scriptVersionId=64871943 by Bhavik\n",
    "* https://www.kaggle.com/daikiiwasaki/decision-forest-fed-by-neural-network by daiki iwasaki\n",
    "* https://www.kaggle.com/jonaspalucibarbosa/tps06-21-keras-nn-with-embedding by Jonas Paluci Barbosa\n",
    "* https://www.kaggle.com/jonaspalucibarbosa/tps06-21-wide-and-deep-nn-w-keras by Jonas Paluci Barbosa\n",
    "* https://www.kaggle.com/hiro5299834/tps06-nn-w-discrete-and-continuous-features by BIZEN\n",
    "* https://www.kaggle.com/hiro5299834/tps06-nn-embedding-conv1d/output?scriptVersionId=64882293&select=submission.csv by BIZEN\n",
    "* https://www.kaggle.com/fusioncenter/residual-network-for-tabular-data by Shachar Y.\n",
    "* https://www.kaggle.com/mehrankazeminia/1-tps-jun-21-histgradient-catboost-nn by Mehran Kazeminia and by Somayyeh Gholami\n",
    "* https://www.kaggle.com/mehrankazeminia/2-tps-jun-21-comparative-method-for-classifier/output?select=submission_ens.csv by Mehran Kazeminia and by Somayyeh Gholami\n",
    "* https://www.kaggle.com/tensorchoko/lightautoml-tps-june-2021 by tensor choko\n",
    "* https://www.kaggle.com/lukaszborecki/tps-06-tensorflow-work-in-progress-book/output?scriptVersionId=65426996&select=embmodel.csv by Lukasz Borecki\n",
    "* https://www.kaggle.com/boss0ayush/simple-nn-implementation-for-beginners-top-7 by Ayush Shrivastava\n",
    "* https://www.kaggle.com/vineethakkinapalli/tps-06-21-5-auto-ml-2-optuna by Vineeth\n",
    "* https://www.kaggle.com/munumbutt/autogluon-tps by Munum Butt\n",
    "* https://www.kaggle.com/dlaststark/tps-june-entity-embeddings-lstm by DLastStark\n",
    "* https://www.kaggle.com/dlaststark/tps-june-dae-entity-embeddings-1d-cnn/output?select=DNN_submission.csv by DLastStark\n",
    "* https://www.kaggle.com/dlaststark/tps-june-entity-embeddings-1d-cnn/output?select=DNN_submission.csv by DLastStark\n",
    "* https://www.kaggle.com/jenssvensmark/tabular-play-jun-tf-cat/output?scriptVersionId=65723419 by Jens Svensmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-commercial",
   "metadata": {
    "papermill": {
     "duration": 0.008784,
     "end_time": "2021-06-16T18:30:50.289826",
     "exception": false,
     "start_time": "2021-06-16T18:30:50.281042",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Reference https://www.kaggle.com/mehrankazeminia/2-tps-jun-21-comparative-method-for-classifier\n",
    "#  by Mehran Kazeminia and Somayyeh Gholami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "progressive-substitute",
   "metadata": {
    "papermill": {
     "duration": 0.017508,
     "end_time": "2021-06-16T18:30:50.316263",
     "exception": false,
     "start_time": "2021-06-16T18:30:50.298755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "label = ['Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6',\n",
    "       'Class_7', 'Class_8', 'Class_9']\n",
    "majority = 4   # < 5\n",
    "m_majority = 9  # <= 9\n",
    "NCLASS = len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "silent-prototype",
   "metadata": {
    "papermill": {
     "duration": 0.032595,
     "end_time": "2021-06-16T18:30:50.357751",
     "exception": false,
     "start_time": "2021-06-16T18:30:50.325156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the max number of files is 5\n",
    "# input format: pd.DataFrame\n",
    "\n",
    "\n",
    "def blend(a, b, c = 0, d = 0, e = 0):\n",
    "    if (not isinstance(c, pd.DataFrame)) and (not isinstance(d, pd.DataFrame)) and (not isinstance(e, pd.DataFrame)):\n",
    "        output = a.copy()   # 0.61 + 0.39\n",
    "        for i in label:\n",
    "            output[i] = a[i] * 0.61 + b[i] * 0.39\n",
    "    elif (not isinstance(d, pd.DataFrame)) and (not isinstance(e, pd.DataFrame)):\n",
    "        output = a.copy() # 0.52 + 0.32 + 0.16 \n",
    "        for i in label:\n",
    "            output[i] = a[i] * 0.52 + b[i] * 0.32 + c[i] * 0.16\n",
    "    elif (not isinstance(e, pd.DataFrame)):\n",
    "        output = a.copy()  # 0.48 + 0.29 + 0.17 + 0.06\n",
    "        for i in label:\n",
    "            output[i] = a[i] * 0.48 + b[i] * 0.27 + c[i] * 0.17 + d[i] * 0.06 \n",
    "    else: # 0.44 + 0.27 + 0.17 + 0.09 + 0.03\n",
    "        output = a.copy()\n",
    "        for i in label:\n",
    "            output[i] = a[i] * 0.44 + b[i] * 0.27 + c[i] * 0.17 + d[i] * 0.09 + e[i] * 0.03\n",
    "        av = a.values\n",
    "        bv = b.values\n",
    "        cv = c.values\n",
    "        dv = d.values\n",
    "        ev = e.values  \n",
    "        imp = output.copy()\n",
    "        impv = imp.values\n",
    "        number = 0  \n",
    "        for i in range (len(output)):\n",
    "            c_count = 0  \n",
    "            row = impv[i,1:]\n",
    "            row_sort = np.sort(row)        \n",
    "            row5 = av[i,1:]\n",
    "            row4 = bv[i,1:]\n",
    "            row3 = cv[i,1:]\n",
    "            row2 = dv[i,1:]\n",
    "            row1 = ev[i,1:]        \n",
    "            row1_sort = np.sort(row1)\n",
    "            row2_sort = np.sort(row2)\n",
    "            row3_sort = np.sort(row3)\n",
    "            row4_sort = np.sort(row4)\n",
    "            row5_sort = np.sort(row5)\n",
    "            for j in range (NCLASS): \n",
    "                count = 0\n",
    "                for k in range (NCLASS):                \n",
    "                    if (row5[j] == row5_sort[k]):                     \n",
    "                        if (row1[j] == row1_sort[k]):\n",
    "                            count = count + 1\n",
    "                        if (row2[j] == row2_sort[k]):\n",
    "                            count = count + 1                   \n",
    "                        if (row3[j] == row3_sort[k]):\n",
    "                            count = count + 1   \n",
    "                        if (row4[j] == row4_sort[k]):\n",
    "                            count = count + 1 \n",
    "                if (count >= majority):\n",
    "                    c_count = c_count + 1\n",
    "            if ((c_count >= m_majority) and (row5_sort[8] >= row_sort[8])): \n",
    "                impv[i, 1:] = row5            \n",
    "                number = number + 1            \n",
    "        imp.iloc[:, 1:] = impv[:, 1:]\n",
    "        p_number = round(((number / 100000) * 100),2)   \n",
    "        output = imp\n",
    "    output[label] = np.clip(output[label], 0.002400, 0.95)   # (0.002500, 0.941)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "thick-title",
   "metadata": {
    "papermill": {
     "duration": 0.037562,
     "end_time": "2021-06-16T18:30:50.404187",
     "exception": false,
     "start_time": "2021-06-16T18:30:50.366625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all the combinations\n",
    "# the max number of combinations is 26\n",
    "\n",
    "def generate(a, b, c = 0, d = 0, e = 0):\n",
    "    if (not isinstance(c, pd.DataFrame)) and (not isinstance(d, pd.DataFrame)) and (not isinstance(e, pd.DataFrame)):\n",
    "        ab = blend(a, b)\n",
    "        ab.to_csv('ab.csv',index=False)\n",
    "    elif (not isinstance(d, pd.DataFrame)) and (not isinstance(e, pd.DataFrame)):\n",
    "        ab = blend(a, b)\n",
    "        ab.to_csv('ab.csv',index=False)\n",
    "        ac = blend(a, c)\n",
    "        ac.to_csv('ac.csv',index=False)\n",
    "        bc = blend(b, c)\n",
    "        bc.to_csv('bc.csv',index=False)  \n",
    "        abc = blend(a, b, c)\n",
    "        abc.to_csv('abc.csv',index=False)\n",
    "    elif (not isinstance(e, pd.DataFrame)):\n",
    "        ab = blend(a, b)\n",
    "        ab.to_csv('ab.csv',index=False)\n",
    "        ac = blend(a, c)\n",
    "        ac.to_csv('ac.csv',index=False)\n",
    "        ad = blend(a, d)\n",
    "        ad.to_csv('ad.csv',index=False)\n",
    "        bc = blend(b, c)\n",
    "        bc.to_csv('bc.csv',index=False)\n",
    "        bd = blend(b, d)\n",
    "        bd.to_csv('bd.csv',index=False)\n",
    "        cd = blend(c, d)\n",
    "        cd.to_csv('cd.csv',index=False)   \n",
    "        abc = blend(a, b, c)\n",
    "        abc.to_csv('abc.csv',index=False)\n",
    "        abd = blend(a, b, d)\n",
    "        abd.to_csv('abd.csv',index=False)\n",
    "        acd = blend(a, c, d)\n",
    "        acd.to_csv('acd.csv',index=False)\n",
    "        bcd = blend(b, c, d)\n",
    "        bcd.to_csv('bcd.csv',index=False)\n",
    "        bde = blend(b, d, e) \n",
    "        abcd = blend(a, b, c, d)\n",
    "        abcd.to_csv('abcd.csv',index=False)\n",
    "    else:\n",
    "        ab = blend(a, b)\n",
    "        ab.to_csv('ab.csv',index=False)\n",
    "        ac = blend(a, c)\n",
    "        ac.to_csv('ac.csv',index=False)\n",
    "        ad = blend(a, d)\n",
    "        ad.to_csv('ad.csv',index=False)\n",
    "        ae = blend(a, e)\n",
    "        ae.to_csv('ae.csv',index=False)\n",
    "        bc = blend(b, c)\n",
    "        bc.to_csv('bc.csv',index=False)\n",
    "        bd = blend(b, d)\n",
    "        bd.to_csv('bd.csv',index=False)\n",
    "        be = blend(b, e)\n",
    "        be.to_csv('be.csv',index=False)\n",
    "        cd = blend(c, d)\n",
    "        cd.to_csv('cd.csv',index=False)\n",
    "        ce = blend(c, e)\n",
    "        ce.to_csv('ce.csv',index=False)\n",
    "        de = blend(d, e)\n",
    "        de.to_csv('de.csv',index=False)     \n",
    "        abc = blend(a, b, c)\n",
    "        abc.to_csv('abc.csv',index=False)\n",
    "        abd = blend(a, b, d)\n",
    "        abd.to_csv('abd.csv',index=False)\n",
    "        abe = blend(a, b, e)\n",
    "        abe.to_csv('abe.csv',index=False)\n",
    "        acd = blend(a, c, d)\n",
    "        acd.to_csv('acd.csv',index=False)\n",
    "        ace = blend(a, c, e)\n",
    "        ace.to_csv('ace.csv',index=False)\n",
    "        ade = blend(a, d, e)\n",
    "        ade.to_csv('ade.csv',index=False)\n",
    "        bcd = blend(b, c, d)\n",
    "        bcd.to_csv('bcd.csv',index=False)\n",
    "        bce = blend(b, c, e)\n",
    "        bce.to_csv('bce.csv',index=False)\n",
    "        bde = blend(b, d, e)\n",
    "        bde.to_csv('bde.csv',index=False)\n",
    "        cde = blend(c, d, e)\n",
    "        cde.to_csv('cde.csv',index=False)  \n",
    "        abcd = blend(a, b, c, d)\n",
    "        abcd.to_csv('abcd.csv',index=False)\n",
    "        abce = blend(a, b, c, e)\n",
    "        abce.to_csv('abce.csv',index=False)\n",
    "        abde = blend(a, b, d, e)\n",
    "        abde.to_csv('abde.csv',index=False)\n",
    "        acde = blend(a, c, d, e)\n",
    "        acde.to_csv('acde.csv',index=False)\n",
    "        bcde = blend(b, c, d, e)\n",
    "        bcde.to_csv('bcde.csv',index=False)\n",
    "        abcde = blend(a, b, c, d, e)\n",
    "        abcde.to_csv('abcde.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-stewart",
   "metadata": {
    "papermill": {
     "duration": 0.00883,
     "end_time": "2021-06-16T18:30:50.421845",
     "exception": false,
     "start_time": "2021-06-16T18:30:50.413015",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "use generate() method to get the blending results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "equipped-fraction",
   "metadata": {
    "papermill": {
     "duration": 63.437036,
     "end_time": "2021-06-16T18:31:53.867741",
     "exception": false,
     "start_time": "2021-06-16T18:30:50.430705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../input/tps-june-files/Keras_1.74485.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-e1a65f76e24e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfile51\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../input/tps-june-files/Keras_1.74485.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfile52\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../input/tps-june-files/embmodel 1.7449.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfile53\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../input/tps-june-files/Keras_1.74491.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfile54\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../input/tps-june-files/NN_blending 1.74501.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfile55\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../input/tps-june-files/lightautoml_1.74513.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1048\u001b[0m             )\n\u001b[0;32m   1049\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1050\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1051\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1865\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"encoding\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"compression\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m         \"\"\"\n\u001b[1;32m-> 1362\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python38\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/tps-june-files/Keras_1.74485.csv'"
     ]
    }
   ],
   "source": [
    "file51 = pd.read_csv(\"../input/tps-june-files/Keras_1.74485.csv\") \n",
    "file52 = pd.read_csv(\"../input/tps-june-files/embmodel 1.7449.csv\")\n",
    "file53 = pd.read_csv(\"../input/tps-june-files/Keras_1.74491.csv\")\n",
    "file54 = pd.read_csv(\"../input/tps-june-files/NN_blending 1.74501.csv\")\n",
    "file55 = pd.read_csv(\"../input/tps-june-files/lightautoml_1.74513.csv\")\n",
    "generate(file51, file52, file53, file54, file55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "saving-devices",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T18:31:53.894520Z",
     "iopub.status.busy": "2021-06-16T18:31:53.893779Z",
     "iopub.status.idle": "2021-06-16T18:32:19.100195Z",
     "shell.execute_reply": "2021-06-16T18:32:19.099501Z",
     "shell.execute_reply.started": "2021-06-15T21:41:44.846985Z"
    },
    "papermill": {
     "duration": 25.222986,
     "end_time": "2021-06-16T18:32:19.100336",
     "exception": false,
     "start_time": "2021-06-16T18:31:53.877350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "file1 = pd.read_csv(\"../input/tps-june-files/imp 1.74408.csv\")\n",
    "\n",
    "file2 = pd.read_csv(\"../input/tps-june-files/HistGradient 1.74415.csv\")\n",
    "\n",
    "file3 = pd.read_csv(\"../input/tps-june-files/imp 1.74426.csv\")\n",
    "\n",
    "file41 = pd.read_csv(\"../input/tps-june-files/HistGradientCatNN 1.74434.csv\")\n",
    "file42 = pd.read_csv(\"../input/tps-june-files/Residual 1.7442.csv\") # 1.74442\n",
    "file43 = pd.read_csv(\"../input/tps-june-files/residual network R 1.74450.csv\")\n",
    "file44 = pd.read_csv(\"../input/tps-june-files/Sol 1.74456.csv\")\n",
    "file45 = pd.read_csv(\"../input/tps-june-files/Keras_1.74481.csv\")\n",
    "file4 = blend(file41, file42, file43, file44, file45)\n",
    "\n",
    "file51 = pd.read_csv(\"../input/tps-june-files/Keras_1.74485.csv\") \n",
    "file52 = pd.read_csv(\"../input/tps-june-files/embmodel 1.7449.csv\")\n",
    "file53 = pd.read_csv(\"../input/tps-june-files/Keras_1.74491.csv\")\n",
    "file54 = pd.read_csv(\"../input/tps-june-files/NN_blending 1.74501.csv\")\n",
    "file55 = pd.read_csv(\"../input/tps-june-files/lightautoml_1.74513.csv\")\n",
    "file5 = blend(file51, file52, file53, file54, file55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "future-upper",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-16T18:32:19.124444Z",
     "iopub.status.busy": "2021-06-16T18:32:19.123198Z",
     "iopub.status.idle": "2021-06-16T18:33:20.550552Z",
     "shell.execute_reply": "2021-06-16T18:33:20.549965Z",
     "shell.execute_reply.started": "2021-06-15T21:42:28.196685Z"
    },
    "papermill": {
     "duration": 61.441452,
     "end_time": "2021-06-16T18:33:20.550726",
     "exception": false,
     "start_time": "2021-06-16T18:32:19.109274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate(file1, file2, file3, file4, file5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 160.979708,
   "end_time": "2021-06-16T18:33:21.852527",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-06-16T18:30:40.872819",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
